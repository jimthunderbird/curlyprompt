[promptcache]
directory = ".promptcache"

[python]
version = "3.11"

[codegen]
agent = "copilot_cli"

[agent.ollama_qwen]
mode = "cli"
model = "qwen3-coder:30b"
command = 'cat <prompt_cache_directory>/_realtime_prompt.prompt | ollama run <model>'

[agent.copilot_cli]
mode = "cli"
model = ""
command = 'cat <prompt_cache_directory>/_realtime_prompt.prompt | copilot --model gpt-5'
